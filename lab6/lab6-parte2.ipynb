{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GxLyX9vdCnf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA2/blob/main/lab6/lab6-parte2.ipynb)\n",
        "# Práctica 6: Redes neuronales convolucionales - Complicando la CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zjhho6Jb6-j"
      },
      "source": [
        "### Pre-requisitos. Instalar paquetes\n",
        "Usaremos las mismas librerías que para la parte 1. En esta ocasión utilizaremos la GPU, así que declaramos la variable `device`. Recuerda enviar tus modelos al device cuando los instancies (`m = MiModelo().to(device)`) y de enviar también los tensores de datos en el bucle de entrenamiento (`X_batch = X_batch.to(device)` y lo mismo para las etiquetas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjX2mh1-GSga",
        "outputId": "04644ad1-31bf-496c-f9f3-05152850a3fb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Semilla para reproducibilidad\n",
        "seed = 1234567\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd9GpQD5WVY4"
      },
      "source": [
        "### Carga del conjunto de datos\n",
        "\n",
        "En esta ocasión trabajaremos con el conjunto de imágenes *cifar10*, que son imágenes con tres canales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "VpIgeACxjG87",
        "outputId": "5b2225f0-a9e2-4f3a-fbcd-cff2f0490efb"
      },
      "outputs": [],
      "source": [
        "# Los datos de CIFAR se estandarizan utilizando su media y desviación típicas, que aquí vienen precalculadas.\n",
        "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar10_std = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # TODO - Usa transforms.Normalize para estandarizar\n",
        "])\n",
        "\n",
        "train_val = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "# TODO - Divide train_val en train y val (80/20)\n",
        "\n",
        "# TODO - Crea los DataLoaders\n",
        "batch_size = 128\n",
        "train_loader = ...\n",
        "val_loader = ...\n",
        "test_loader = ...\n",
        "\n",
        "# Mostramos un ejemplo del conjunto\n",
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape)  # [128, 3, 32, 32]\n",
        "print(labels.shape)  # [128]\n",
        "\n",
        "# Para mostrar los datos con pyplot hay que deshacer la normalización y poner los canales como última dimensión del tensor\n",
        "def unnormalize(img):\n",
        "    img = img.permute(1,2,0)  # CHW -> HWC\n",
        "    img = img * torch.tensor(cifar10_std) + torch.tensor(cifar10_mean)\n",
        "    return img.clamp(0,1)\n",
        "\n",
        "plt.imshow(unnormalize(images[0]))\n",
        "plt.xlabel(labels[0].item())\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oR1FffxjG8_"
      },
      "source": [
        "## Creando el modelo y entrenando el modelo\n",
        "Para este problema vamos a utilizar la siguiente arquitectura:\n",
        "1. [Convolución 2D](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) de 32 filtros y tamaño de kernel 3, con activación ReLU\n",
        "1. [Pooling 2D](https://docs.pytorch.org/docs/2.8/generated/torch.nn.MaxPool2d.html) tomando el máximo de cada grupo de 2x2\n",
        "1. [Convolución 2D](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) de 64 filtros y tamaño de kernel 3, con activación ReLU\n",
        "1. [Pooling 2D](https://docs.pytorch.org/docs/2.8/generated/torch.nn.MaxPool2d.html) tomando el máximo de cada grupo de 2x2\n",
        "1. [Convolución 2D](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) de 64 filtros y tamaño de kernel 3, con activación ReLU\n",
        "1. Capa Densa (requiere aplanado previo) de 64 unidades y activación ReLU\n",
        "1. Capa de salida\n",
        "\n",
        "Define el modelo y haz el entrenamiento como en la anterior parte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrIOT-4DmRuu"
      },
      "outputs": [],
      "source": [
        "# TODO Define el modelo\n",
        "# TODO Define las funciones de aprendizaje y evaluación\n",
        "# TODO Realiza el entrenamiento\n",
        "# TODO Examina las curvas de entrenamiento y mide el rendimiento en test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ExBje4wgvDE"
      },
      "source": [
        "Si todo ha ido bien, deberías haber obtenido una preción en test de al menos un 60%, lo cual no es desdeñable para una red sencilla.\n",
        "\n",
        "## Mejora del rendimiento\n",
        "Vuelve sobre la arquitectura del modelo e incluye capas de [BatchNorm2d](https://docs.pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) después de cada capa convolucional. Esto hará que las salidas de esa capa se estandaricen para que sigan una distribución N(0,1) (la operación de estandarización se incluye en el grafo y, por tanto, el cómputo de los gradientes). El efecto de esta capa es que se evitará que el gradiente del lote tenga una gran componente solo dedicada a acercar las salidas a la media/desviación de las muestras en cada capa. En consecuencia, el aprendizaje se acelera.\n",
        "\n",
        "### Ejercicios\n",
        " - Repite el entrenamiento con la nueva arquitectura. ¿Qué efecto has notado? ¿Puedes mejorar el rendimiento en test utilizando conceptos vistos en Laboratorios anteriores?\n",
        " - Prueba distintas arquitecturas e intenta mejorar el rendimiento en test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJ8MKjdjG9B",
        "outputId": "6dde8946-5925-489f-e1d1-82aa5318d470"
      },
      "outputs": [],
      "source": [
        "# TODO Define el nuevo modelo\n",
        "# TODO Define las funciones de aprendizaje y evaluación\n",
        "# TODO Realiza el entrenamiento\n",
        "# TODO Examina las curvas de entrenamiento y mide el rendimiento en test"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aa2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
