{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4_parte2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GxLyX9vdCnf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA2/blob/main/lab4/lab4_parte2.ipynb)\n",
        "# Práctica 4: Redes neuronales usando Keras con Regularización\n",
        "## Parte 2. Penalización basada en la norma de los parámetros\n",
        "\n",
        "En esta segunda parte analizaremos cómo realizar una regularización basada en la norma de los parámetros tanto L2 como L1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zjhho6Jb6-j"
      },
      "source": [
        "## Pre-requisitos. Instalar paquetes\n",
        "\n",
        "Para la primera parte de este Laboratorio 4 necesitaremos TensorFlow, TensorFlow-Datasets y otros paquetes para inicializar la semilla y poder reproducir los resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjX2mh1-GSga"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "#Fijamos la semilla para poder reproducir los resultados\n",
        "seed=1234\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyTV4jfNeiRk"
      },
      "source": [
        "Además, cargamos también APIs que vamos a emplear para que el código quede más legible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3-nLMx-enlq"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import InputLayer\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd9GpQD5WVY4"
      },
      "source": [
        "##Cargamos el conjunto de datos\n",
        "\n",
        "Cargamos el conjunto *german_credit_numeric* tal y como hicimos en la parte 1 de este laboratorio.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpsZlN_mEj7D"
      },
      "source": [
        "# Cargamos el conjunto de datos\n",
        "ds_train = tfds.load('german_credit_numeric', split='train[:50%]',  as_supervised=True).batch(128)\n",
        "ds_test = tfds.load('german_credit_numeric', split='train[50%:]', as_supervised=True).batch(128)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNSojR94dP3y"
      },
      "source": [
        "También vamos a establecer la función de pérdida, el algoritmo que vamos a emplear para el entrenamiento y la métrica que nos servirá para evaluar el rendimiento del modelo entrenado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXz3n9daGXjG"
      },
      "source": [
        "fn_perdida = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizador = tf.keras.optimizers.Adam(0.001)\n",
        "metrica = tf.keras.metrics.AUC()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENqWLaw7fuxl"
      },
      "source": [
        "## Creamos un modelo *Sequential*\n",
        "Creamos un modelo *Sequential* tal y como se ha hecho en la primera parte de este laboratorio. Pero incluiremos un término de regularización en las capas *Dense*. En Keras tenemos varias opciones para incluirlo:\n",
        "\n",
        "- *kernel_regularizer* actúa sobre los pesos ($W$)\n",
        "- *bias_regularizer* actúa sobre el sesgo ($b$)\n",
        "- *activity_regularizer* intenta reducir la salida de la capa $y$, por lo tanto, reducirá los pesos y ajustará el sesgo.\n",
        "\n",
        "Normalmente se aplica *kernel_regularizer* (tal y como se ha visto en clase de teoría) para evitar que la red se sobreajuste, para introducirlo en Keras solo hace falta indicarlo en la capa correspondiente, indicando el valor del hiperparámetro de regularización $\\alpha$ (por defecto, su valor es 0.01).\n",
        "\n",
        "Existen varias opciones para calcular este término regularizador, aunque las más empleadas (y vistas en teoría son):\n",
        "1. L1, el término regularización se calcula usando el valor absoluto de los pesos, $||\\mathbf{W}||_{1}$ . \n",
        "1. L2, la más utilizada, donde el término de regularización se calcula usando el cuadrado de los pesos, $\\frac{1}{2}||\\mathbf{W}||^2$\n",
        "\n",
        "**TO-DO**: Prueba diferentes términos de regularización e hiperparámetros. Fijate en la diferencia de resultado entre entrenamiento y test.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrIOT-4DmRuu"
      },
      "source": [
        "#Descomentar el término regularizador que se vaya a emplear\n",
        "from tensorflow.keras.regularizers import l2\n",
        "#from tensorflow.keras.regularizers import l1\n",
        "\n",
        "tamano_entrada = 24\n",
        "#TODO- Varía el valor de alpha para ajustar la regularización\n",
        "alpha=0.01\n",
        "h0_size = 20\n",
        "h1_size = 10\n",
        "h2_size = 5\n",
        "#TODO - define el modelo Sequential\n",
        "model = ...\n",
        "#TODO - incluye la capa de entrada\n",
        "model.add(...)\n",
        "#TODO - incluye las unidades de la primera capa Dense\n",
        "model.add( Dense(units=..., kernel_regularizer=l2(alpha),activation='relu'))\n",
        "#TODO - incluye las otras 3 capas Dense con el término de regularización\n",
        "model.add(...)\n",
        "model.add(...)\n",
        "model.add(...)\n",
        "#Construimos el modelo y mostramos \n",
        "model.build()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1AeI0KUuTcC"
      },
      "source": [
        "Completar el método *compile*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U_0GMdHzhpP"
      },
      "source": [
        "#TODO - indicar los parametros del método compile\n",
        "model.compile(...)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx2nvo6G0Qvn"
      },
      "source": [
        "Completar el método *fit* tal y como hemos hecho en los laboratorios anteriores.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EzQDyKfGfuu"
      },
      "source": [
        "num_epochs =  1000\n",
        "#TODO - entrenar el modelo\n",
        "history = model.fit(...)\n",
        "\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UatqCYAh3jjd"
      },
      "source": [
        "Evaluación sobre el conjunto de test (no usado para el entrenamiento)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-utxTvWSq7"
      },
      "source": [
        "#TODO - llamar a evaluate usando el conjunto de test\n",
        "result = model.evaluate(...) \n",
        "print(model.metrics_names)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
