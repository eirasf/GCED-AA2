{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57knM8jrYZ2t"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1PtNR7npOVBVixG2sEepX-b1l754jqWGg?usp=sharing)\n",
    "\n",
    "# Práctica 8: Transfer learning\n",
    "\n",
    "\n",
    "## Pre-requisitos\n",
    "\n",
    "### Instalar paquetes\n",
    "\n",
    "Si la práctica requiere algún paquete de Python, habrá que incluir una celda en la que se instalen. Si usamos un paquete que se ha utilizado en prácticas anteriores, podríamos dar por supuesto que está instalado pero no cuesta nada satisfacer todas las dependencias en la propia práctica para reducir las dependencias entre ellas.\n",
    "\n",
    "### NOTA: En <font color='red'>Google Colab</font> hay que instalar los paquetes EN CADA EJECUCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkaimNJfYZ2w"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de instalación de tensorflow 2.0\n",
    "#%tensorflow_version 2.x\n",
    "# !pip3 install tensorflow  # NECESARIO SOLO SI SE EJECUTA EN LOCAL\n",
    "import tensorflow as tf\n",
    "\n",
    "# Hacemos los imports que sean necesarios\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOch-CnwQttl"
   },
   "source": [
    "# Transfer learning sobre Stanford Dogs\n",
    "\n",
    "Lo que queremos hacer es entrenar un clasificador para que catalogue las distintas clases de perros almacenadas en el dataset Stanford Dogs. Para ello, lo primero que tenemos que hacer es cargar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gXdWDBIEKel"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'stanford_dogs', split=['train', 'test'], with_info=True, as_supervised=True\n",
    ")\n",
    "NUM_CLASSES = ds_info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkaCDOGapMyl"
   },
   "source": [
    "## Preprocesado de los datos\n",
    "\n",
    "Antes de nada, vamos a ver el tamaño que tienen las imágenes de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xjcLa21EKen"
   },
   "outputs": [],
   "source": [
    "# ds_train es un iterable con una tupla (imagen, clase). Vamos a ver la resolución de la imagen\n",
    "for i, element in enumerate(ds_train.take(5)):\n",
    "    print(element[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHwD7iLeWTm1"
   },
   "source": [
    "Como podemos observar, el tamaño de las imágenes es variable y no coincide con el tamaño que esperamos a la entrada de la red. \n",
    "\n",
    "Nuestro primer cometido será el modificar las imágenes para que tengan el tamaño fijo 224x224x3.\n",
    "\n",
    "**<font color='red'>PISTA:</font> puedes usar la función [resize](https://www.tensorflow.org/api_docs/python/tf/image/resize) y la función map, que te permite operar sobre cada elemento de un iterable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aoHeJUGEKeo"
   },
   "outputs": [],
   "source": [
    "## TODO: completa el código en las partes donde hay un None\n",
    "ds_train = ds_train.map(lambda image, label: (None, label))\n",
    "ds_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBWw_ncKh1EA"
   },
   "source": [
    "#### Visualización de los datos\n",
    "Una vez hecho el preprocesado, ya podemos visualizar las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFyHhz4lhvme"
   },
   "outputs": [],
   "source": [
    "def format_label(label):\n",
    "    string_label = label_info.int2str(label)\n",
    "    return string_label.split(\"-\")[1]\n",
    "\n",
    "label_info = ds_info.features[\"label\"]\n",
    "for i, (image, label) in enumerate(ds_train.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    plt.title(\"{}\".format(format_label(np.argmax(label))))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cpyBP_MZdj-"
   },
   "source": [
    "A mayores, cada red preentrenada tiene un preprocesado de los datos propio, que hay que realizar antes de pasárselo al modelo. En el caso de DenseNet121, la función de preprocesado se llama \n",
    "\n",
    "```\n",
    "tf.keras.applications.densenet.preprocess_input\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCuqvBRlXcSa"
   },
   "outputs": [],
   "source": [
    "## TODO: aplica la función de preprocesado a los conjuntos del dataset\n",
    "None\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77mBj__rcrui"
   },
   "source": [
    "La etiqueta es numérica, y hay que convertirla a tipo one_hot con la función [tf.one_hot](https://www.tensorflow.org/api_docs/python/tf/one_hot)\n",
    "\n",
    "**<font color='red'>PISTA:</font> el número de clases se ha almacenado anteriormente en la variable NUM_CLASSES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyPG2DeDadUN"
   },
   "outputs": [],
   "source": [
    "## TODO: convierte las etiquetas a tipo one hot.\n",
    "None\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hSCpabQMlnR"
   },
   "source": [
    "Finalmente, nos queda preparar los datos en batches para pasárselos al entrenamiento. Aquí distinguiremos entre entrenamiento y test, ya que los datos de entrenamiento es mejor hacer los batches de manera aleatoria en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXNa7oG8M9o1"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "ds_train_batch = ds_train.cache().shuffle(batch_size*5).batch(batch_size)\n",
    "ds_test_batch = ds_test.batch(batch_size) # En test no es necesario aleatorizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ttiMl9JlzBR"
   },
   "source": [
    "## Creando el modelo\n",
    "\n",
    "Una vez obtenido un correcto preprocesado de los datos, vamos a crear el modelo. Nuestro modelo constará de tres partes diferenciadas:\n",
    "\n",
    "1. Data augmentation\n",
    "1. DenseNet121 preentrenado\n",
    "1. Clasificador\n",
    "\n",
    "Vamos a ir paso a paso creando cada uno de los puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ry4lvNGKuqC"
   },
   "source": [
    "### Data augmentation\n",
    "\n",
    "El primer paso que vamos a realizar es aumentar los datos de entrenamiento mediante la aplicación de distintas operaciones, que se encuentran en el paquete [tensorflow.keras.layers.experimental.preprocessing](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing). En concreto, vamos a realizar las siguientes operaciones:\n",
    "\n",
    "1. Rotaciones aleatorias de $2*\\pi*0.15$ grados\n",
    "1. Traslaciones aleatorias del $10\\%$ del tamaño de la imagen\n",
    "1. Giros aleatorios de la imagen\n",
    "1. Cambios aleatorios del contraste del $10\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IdcMA7MiU1C"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "## TODO: crea el modelo de data augmentation, rellenando los huecos marcados con None\n",
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        None, # rotaciones\n",
    "        None, # traslaciones\n",
    "        None, # giros\n",
    "        None  # contraste\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QNMcdP4m3Vs"
   },
   "source": [
    "### Descargar un modelo preentrenado\n",
    "\n",
    "\n",
    "Lo primero que vamos a hacer es descargar un modelo preentrenado. Por suerte, en Tensorflow tenemos una serie de modelos ya preentrenados. Se encuentran en el paquete **tensorflow.keras.applications** ([Doc](https://keras.io/api/applications/)). En concreto, vamos a utilizar la red DenseNet121, cuyo esquema podemos ver en la siguiente imagen:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1cINnKtOxOtZGxCiZwSXfhku495KHsSvk)\n",
    "\n",
    "En esencia, es una variante del bloque residual, en donde la salida de una capa se suma a todas las salidas de las capas siguientes.\n",
    "\n",
    "Para cargar el modelo haremos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFxztZQInlAB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Cargamos el modelo. \n",
    "densenet = DenseNet121(\n",
    "    weights='imagenet', # El parámetro weights le dice que cargue los datos de la red ya entrenada sobre el dataset ImageNet\n",
    "    include_top=False, # El parámetro include_top le dice que cargue la última capa con el clasificador\n",
    "    input_shape=(224, 224, 3), # Este parámetro será necesario para hacer transfer learning, \n",
    "                      # pues necesitaremos especificar el tamaño de los datos de entrada\n",
    ")\n",
    "\n",
    "# Comprobamos el tamaño de entrada de la red\n",
    "print('Input shape :', densenet.input_shape)\n",
    "\n",
    "# Comprobamos el tamaño de salida de la red\n",
    "print('Output shape :', densenet.output_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UwKF8f1EKel"
   },
   "source": [
    "\n",
    "En la [documentación](https://keras.io/api/applications/densenet/#densenet121-function) dodemos ver que esta red admite, como entrada, imágenes de tamaño 224x224x3. Aunque podemos utilizar cualquier tamaño de entrada (siempre que sea mayor de 32x32x3), vamos a seguir utilizando ese tamaño.\n",
    "\n",
    "### Crear el clasificador\n",
    "\n",
    "Para crear el clasificador, lo que vamos a hacer es crear una última capa que será un clasificador lineal (capa [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)). Sin embargo, podemos observar que la salida de la red DenseNet tiene 4 dimensiones, no 2 que es lo necesario para crear el clasificador. Aquí tenemos dos opciones para realizar la conversión:\n",
    "\n",
    "1. Usar [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten), en la que la dimensión 2 será de tamaño la multiplicación de las dimensiones 2, 3 y 4.\n",
    "1. Usar GlobalPooling, colapsando las dimensiones 2 y 3, siendo por tanto la dimensión 2 de salida igual a la dimensión 4 de entrada.\n",
    "\n",
    "Aquí podemos ver una imagen ilustrando la diferencia:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1I3a2v7cuEjAUVdlLENtCaIq-etCXriGT)\n",
    "\n",
    "En nuestro caso, vamos a usar un GlobalPooling, en concreto [GlobalAveragePooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D). A mayores, añadiremos alguna regularización extra como [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) o [Batch Normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2-trJ5PV1Fr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "## TODO: crea el clasificador, rellenando los huecos marcados por None\n",
    "classifier = Sequential(\n",
    "    [\n",
    "        None, # GlobalAveragePooling2D\n",
    "        None, # BatchNormalization\n",
    "        None, # Dropout con probabilidad 0.2\n",
    "        None, # Dense con salida el número de clases del dataset\n",
    "        None, # Softmax activation\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj5i_K5obV8w"
   },
   "source": [
    "### Combinando todos los elementos\n",
    "\n",
    "Una vez creados todos los elementos, sólo nos falta combinarlos. Hay que recordar que la red preentrenada no se modifica, por lo que hay que indicarle que los pesos no son entrenables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SA_x68DNbU-Z"
   },
   "outputs": [],
   "source": [
    "## TODO: Crea el modelo final combinando los 3 modelos creados anteriormente\n",
    "\n",
    "input = None  # capa de input, teniendo en cuenta el tamaño de las imágenes \n",
    "\n",
    "input_augmented = None  # aplica el modelo de data augmentation a la capa de entrada\n",
    "\n",
    "densenet.trainable = False\n",
    "densenet_output = None  # aplica el modelo densenet\n",
    "\n",
    "output = None  # aplica el clasificador\n",
    "\n",
    "model = tf.keras.Model(None, None, name=\"DenseNet\")  # crea el modelo final, indicando la entrada y la salida\n",
    "optimizer = None  # define el optimizador. Usaremos un Adam\n",
    "model.compile(\n",
    "    optimizer=None, loss=None, metrics=[None]  # Compila el modelo, usando el optimizador creado, la función de pérdida para clasificación multiclase y la métrica de precisión\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qwFar8Eg3bQ"
   },
   "source": [
    "## Entrenando el modelo\n",
    "\n",
    "Por último, sólo nos queda entrenar el modelo durante 10 iteraciones (ten paciencia, puede llevar sobre 10 minutos). En test, deberíamos tener una precisión cercana al $80\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuFMXGGwfFRT"
   },
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "    ds_train_batch, epochs=10, verbose=1  # se podría poner validation_data=ds_test_batch, y así ver en cada iteración como va, pero en este caso consume mucho tiempo\n",
    ")\n",
    "\n",
    "\n",
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    # plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"train accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    # plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "print('TEST ACCURACY : ', model.evaluate(ds_test_batch)[-1])\n",
    "\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_9t7kOWw3UO"
   },
   "source": [
    "## Fine tunning\n",
    "\n",
    "Al inicio hemos entrenado el modelo sin tocar los pesos de la red DenseNet. Sin embargo, ahora que ya hemos entrenado las capas finales, podemos reentrenar el modelo al completo. Sin embargo, hay que tener en cuenta una serie de consideraciones.\n",
    "\n",
    "- La tasa de aprendizaje tiene que ser muy baja. Un valor alto podría eliminar la calidad del entrenamiento inicial, haciendo que el sistema se comporte de manera similar a entrenarlo desde 0.\n",
    "- Las capas de Batch Normalization se mantienen sin entrenar. Esto es debido a que dificultan el entrenamiento en redes ya entrenadas, y sólo estamos buscando un ajuste fino en el sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLyLgjQaoo55"
   },
   "outputs": [],
   "source": [
    "## TODO: completa aquellos puntos marcados con None\n",
    "batch_size = 32 # Tenemos que bajar el tamaño anterior para no saturar la memoria del sistema\n",
    "ds_train_batch = ds_train.cache().shuffle(batch_size*5).batch(batch_size)\n",
    "ds_test_batch = ds_test.batch(batch_size)\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    # Descongelamos las últimas 20 capas while, dejando BatchNormalization sin entrenar\n",
    "    for layer in model.layers[-20:]:\n",
    "        if not isinstance(layer, None): # Comprueba que la capa no sea de tipo BatchNormalization\n",
    "            None                        # Marca la capa como entrenable\n",
    "\n",
    "    optimizer = None                    # Usa Adam con una tasa de aprendizaje de 1e-5\n",
    "    model.compile(\n",
    "        None, None, None                # define el compilador, la función de coste y la métrica\n",
    "    )\n",
    "\n",
    "None                                    # Llama a la función que has creado sobre nuestro modelo\n",
    "\n",
    "epochs = 8  \n",
    "hist = None  # Llama a la función de entrenamiento sobre el modelo\n",
    "\n",
    "plot_hist(hist)\n",
    "\n",
    "print('TEST ACCURACY : ', model.evaluate(ds_test_batch)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiXL8pks20Up"
   },
   "source": [
    "La precisión en entrenamiento ha subido, pero en test ha bajado. ¿Qué puede estar pasando?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIEsuejQv4mP"
   },
   "source": [
    "# ¡ENHORABUENA! Has completado la práctica de Transfer Learning.\n",
    "\n",
    "# ¿Deseas saber más?\n",
    "\n",
    "El transfer learning no se limita sólo a entrenar las últimas capas. Se pueden utilizar sólo unas pocas capas preentrenadas, y entrenar el resto. No hay límite sobre lo que se puede hacer. Tampoco se restringe a clasificación únicamente. Las *deep features* de un modelo de clasificación suelen ser útiles para modelos de regresión, segmentación, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QIu2fE3tIHA"
   },
   "source": [
    "# Trabajo extra\n",
    "\n",
    "Como trabajo extra, se propone realizar una idea parecida, pero con dificultad añadida.\n",
    "\n",
    "- El dataset a utilizar será [cifar10](https://www.tensorflow.org/datasets/catalog/cifar10).\n",
    "- Se utilizará una entrada de la red de 32x32x3.\n",
    "- La red preentrenada a utilizar será [MobileNetV3Small](https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Small).\n",
    "- Puedes escoger el calsificador que quieras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMavrtMX_7V7"
   },
   "outputs": [],
   "source": [
    "# TODO: escribe el código para el trabajo extra sin ayuda. Usa todos los bloques de código que quieras."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "8_transfer_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
