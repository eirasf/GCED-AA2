{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GxLyX9vdCnf"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA2/blob/main/lab6/lab6-parte1.ipynb)\n",
    "# Práctica 6: Redes neuronales convolucionales - Parte 1 - FF vs CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zjhho6Jb6-j"
   },
   "source": [
    "### Pre-requisitos. Instalar paquetes\n",
    "\n",
    "Para la primera parte de este Laboratorio 6 necesitaremos, además de torch, el módulo torchvision para cargar los datos. Además, como habitualmente, fijaremos la semilla aleatoria para asegurar la reproducibilidad de los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjX2mh1-GSga"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Fijamos la semilla para reproducibilidad\n",
    "seed = 1234567\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd9GpQD5WVY4"
   },
   "source": [
    "### Carga del conjunto de datos\n",
    "\n",
    "En esta ocasión trabajaremos con el conjunto de imágenes *mnist*, que representa dígitos escritos a mano. Debemos indicar a nuestro dataloader que haga lotes de 128 elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos MNIST usando torchvision\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convierte a tensor y escala a [0,1]\n",
    "])\n",
    "\n",
    "train_val = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# TODO - Divide train_val en train y val (80/20)\n",
    "\n",
    "# TODO - Crea los DataLoaders\n",
    "batch_size = 128\n",
    "train_loader = ...\n",
    "val_loader = ...\n",
    "test_loader = ...\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "IMAGE_SHAPE = (1, 28, 28)\n",
    "\n",
    "# Para comprobar que se ha cargado tomamos un elemento y lo mostramos\n",
    "im_batch, label_batch = next(iter(train_loader))\n",
    "ej_imagen = im_batch[0]\n",
    "plt.imshow(ej_imagen.squeeze())\n",
    "plt.xlabel(f'Label: {label_batch[0].item()}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando los datos con un red neuronal feed-forward\n",
    "\n",
    "Vamos a modelar los datos con una red feed-forward que tenga capas de 40, 25 y 16 unidades (todas con activación ReLU). Debemos tener en cuenta que las imágenes son tensores de dimensión 3 (su `shape` es (1,28,28)), mientras que la entrada de nuestras capas Dense debe ser un tensor de dimensión 1. Para adecuar la entrada a lo que necesitamos, vamos a \"aplanar\" los tensores de las imágenes, que pasarán de `shape` (28,28,1) a `shape` (784). Para ello aplanaremos el lote de (128,1,28,28) a (128, 784) en la función `forward`.\n",
    "\n",
    "Por último, la salida de nuestro modelo debe tener tantas componentes como clases distintas tiene el conjunto. Como queremos que la salida aproxime la probabilidad de las distintas clases, lo habitual sería poner una función de activación *softmax*, pero en este caso, por razones de eficiencia del entrenamiento, es mejor dejar una salida lineal y posteriormente usar la función de pérdida `nn.CrossEntropyLoss` que espera las salidas vienen en ese formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KrIOT-4DmRuu",
    "outputId": "79dba569-e5e5-426f-9a87-57757db7d363"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # TODO - Completa la clase siguiendo las instrucciones dadas en la celda anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNSojR94dP3y"
   },
   "source": [
    "### Entrenamiento del modelo\n",
    "Vamos a establecer la función de pérdida, el optimizador (Adam con el LR por defecto) y la métrica que nos servirá para evaluar el rendimiento del modelo entrenado (precisión categórica).\n",
    "\n",
    "Como intentamos predecir una clase entre varias, nuestra función de pérdida debe ser la [entropía cruzada](https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Le indicaremos que la salida de nuestra red como *logits* y las etiquetas con el valor numérico de la clase (no en one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación sobre el conjunto de test\n",
    "def evaluate(model, dataloader, loss_fn):\n",
    "    # TODO - Completa la función para que devuelva la pérdida y la tasa de acierto\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, loss_fn, optimizer, num_epochs=16):\n",
    "    # TODO - Completa la función para que haga el entrenamiento devuelva el histórico de pérdidas y tasas de acierto\n",
    "\n",
    "# TODO - Define el modelo, función de pérdida y optimizador (Adam con lr=0.001) y haz el entrenamiento durante 16 epochs\n",
    "ff_model = ...\n",
    "loss_fn = ...\n",
    "optimizer = ...\n",
    "train_losses, val_losses = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación del rendimiento\n",
    "Aprovecharemos el conjunto de test para comprobar la capacidad de generalización de nuestro modelo. Puedes también visualizar la curva de entrenamiento para identificar potenciales problemas con el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Evalúa sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo ha ido correctamente deberías haber obtenido un valor de precisión sobre el conjunto de test comparable a los obtenidos con los conjuntos de entrenamiento y validación, lo que indica que el modelo generaliza bien a otros datos del conjunto original pero... ¿tenemos un buen modelo?\n",
    "\n",
    "Vamos a comprobar la robustez del modelo haciendo pequeños desplazamientos de las imágenes originales. Utilizaremos un pequeño modelo que aplique una traslación aleatoria de hasta un 10% del tamaño de la imagen a cada una de las imágenes de test. Nos ayudaremos del módulo `transforms` incluido en `torchvision` y en particular de [`transforms.RandomAffine`](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.RandomAffine.html) para hacer traslacciones de hasta un 10% del tamaño de imagen en cualquier dirección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation: aplicamos una pequeña traslación usando torchvision.transforms\n",
    "transform_translated = transforms.Compose([\n",
    "    # TODO - Utiliza RandomAffine para hacer traslacciones de hasta un 10% en cualquier dirección\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Creamos un dataset de test transformado\n",
    "test_translated = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_translated)\n",
    "test_translated_loader = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos ahora la precisión sobre este nuevo conjunto de imágenes que han sido ligeramente desplazadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Evalúa sobre el conjunto de test desplazado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo ha ido bien, deberías haber comprobado que estas pequeñas traslaciones son suficientes para que la precisión del modelo baje sustancialmente. Las redes feed-forward no son robustas ante este tipo de perturbaciones.\n",
    "\n",
    "## Comparativa con una red convolucional\n",
    "\n",
    "Declara ahora un modelo convolucional con la siguiente arquitectura:\n",
    " 1. [Convolución 2D](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) de 8 filtros y tamaño de kernel 3, con activación ReLU\n",
    " 1. [Pooling 2D](https://docs.pytorch.org/docs/2.8/generated/torch.nn.MaxPool2d.html) tomando el máximo de cada grupo de 2x2\n",
    "  1. [Convolución 2D](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) de 8 filtros y tamaño de kernel 3, con activación ReLU\n",
    " 1. [Pooling 2D](https://docs.pytorch.org/docs/2.8/generated/torch.nn.MaxPool2d.html) tomando el máximo de cada grupo de 2x2\n",
    " 1. Capa Densa (requiere aplanado previo) de 32 unidades y activación ReLU\n",
    " 1. Capa de salida\n",
    " \n",
    "Define el nuevo modelo, entrénalo y haz las verificaciones posteriores para observar la diferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    # TODO - Completa la clase según las instrucciones\n",
    "\n",
    "# TODO - Define el modelo, función de pérdida y optimizador (Adam con lr=0.001) y haz el entrenamiento durante 16 epochs\n",
    "conv_model = ...\n",
    "loss_fn = ...\n",
    "optimizer = ...\n",
    "train_losses, val_losses = ...\n",
    "\n",
    "# TODO - Haz las evaluaciones como en hiciste con ff_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexiones sobre la comparativa\n",
    " - ¿Qué has observado en el rendimiento?\n",
    " - ¿Cuántos parámetros tiene la red convolucional respecto a la *feed-forward*\n",
    " - ¿Cómo ha cambiado el tiempo de ejecución?\n",
    " - ¿Es más robusta frente a los desplazamientos esta red?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab4_parte1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aa2-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
