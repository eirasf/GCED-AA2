{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4_parte3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GxLyX9vdCnf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA2/blob/main/lab4/lab4_parte3.ipynb)\n",
        "# Práctica 4: Redes neuronales usando Keras con Regularización\n",
        "## Parte 3. Dropout\n",
        "\n",
        "En esta tercera parte, veremos cómo tratar el *overfitting* mediante la técnica de *Dropout* que consiste en usar un solo modelo para simular tener una gran cantidad de arquitecturas de red diferentes de las que se van eliminando nodos aleatoriamente durante el entrenamiento. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zjhho6Jb6-j"
      },
      "source": [
        "## Pre-requisitos. Instalar paquetes\n",
        "\n",
        "Al igual que en las partes anteriores de este Laboratorio 4, necesitaremos TensorFlow, TensorFlow-Datasets y otros paquetes para inicializar la semilla y poder reproducir los resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjX2mh1-GSga"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "#Fijamos la semilla para poder reproducir los resultados\n",
        "seed=1234\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyTV4jfNeiRk"
      },
      "source": [
        "Además, cargamos también APIs que vamos a emplear para que el código quede más legible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3-nLMx-enlq"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import InputLayer\n",
        "from keras.layers import Dense\n",
        "# Incluímos la capa de Keras que nos permitirá hacer Dropout\n",
        "from keras.layers import Dropout\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd9GpQD5WVY4"
      },
      "source": [
        "##Cargamos el conjunto de datos\n",
        "\n",
        "De nuevo, seguimos empleando el conjunto *german_credit_numeric*, dividiendo en entrenamiento y test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpsZlN_mEj7D"
      },
      "source": [
        "# Cargamos el conjunto de datos\n",
        "ds_train = tfds.load('german_credit_numeric', split='train[:50%]',  as_supervised=True).batch(128)\n",
        "ds_test = tfds.load('german_credit_numeric', split='train[50%:]', as_supervised=True).batch(128)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNSojR94dP3y"
      },
      "source": [
        "Establecer la función de pérdida, el algoritmo que vamos a emplear para el entrenamiento y la métrica que nos servirá para evaluar el rendimiento del modelo entrenado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXz3n9daGXjG"
      },
      "source": [
        "#Indicamos la función de perdida, el algoritmo de optimización y la métrica para evaluar el rendimiento \n",
        "fn_perdida = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizador = tf.keras.optimizers.Adam(0.001)\n",
        "metrica = tf.keras.metrics.AUC()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENqWLaw7fuxl"
      },
      "source": [
        "## Creamos un modelo *Sequential* con capas *Dropout*\n",
        "La forma más simple de crear *Dropout* en Keras nos la proporciona la capa *Dropout*. Cuando se crea la capa *Dropout* se puede especificar la probabilidad de poner cada entrada a cero. Así, estableciendo una tasa de deserción a 0.2 indica que el 20% de las entradas estará a 0.\n",
        "La capa *Dropout* se agrega a un modelo entre capas existentes y se aplica a las salidas de la capa anterior, antes de alimentar a la siguiente.\n",
        "\n",
        "\n",
        "Recomendaciones para usar *Dropout*:\n",
        "1. Utilizar una tasa de abandono pequeña del 20% al 50% de las neuronas, el 20% constituye un buen punto de partida. Una probabilidad demasiado baja tiene un efecto mínimo y un valor demasiado alto da como resultado *underfitting* por parte de la red.\n",
        "\n",
        "1. Red grande. Es probable que se obtenga un mejor rendimiento cuando se utiliza *Dropout* con una red más grande, lo que le da al modelo una mayor oportunidad para aprender representaciones independientes.\n",
        "1. Emplear *Dropout* tanto en la capa de entrada como en las capas ocultas. \n",
        "\n",
        "**TO-DO**: Cambia el ratio de abandono en las distintas capas y evalúa las diferencias entre entrenamiento y test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrIOT-4DmRuu"
      },
      "source": [
        "tamano_entrada = 24\n",
        "h0_size = 20\n",
        "h1_size = 10\n",
        "h2_size = 5\n",
        "#TODO - define el modelo Sequential\n",
        "model =  ...\n",
        "#TODO - incluye la capa de entrada \n",
        "model.add(....)))\n",
        "model.add( Dropout(0.2))\n",
        "#TODO - incluir el resto de capas Dense y Dropout\n",
        "model.add( ...))\n",
        "model.add( ...)\n",
        "model.add( ...)\n",
        "model.add( ...)\n",
        "model.add( ...)\n",
        "model.add( ...)\n",
        "model.add( ...)\n",
        "#Construimos el modelo y mostramos \n",
        "model.build()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1AeI0KUuTcC"
      },
      "source": [
        "Completar el método *compile*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U_0GMdHzhpP"
      },
      "source": [
        "#TODO - indicar los parametros del método compile\n",
        "model.compile(...)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx2nvo6G0Qvn"
      },
      "source": [
        "Completar el método *fit* tal y como hemos hecho en los laboratorios anteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EzQDyKfGfuu"
      },
      "source": [
        "#TODO - entrenar el modelo\n",
        "num_epochs =  700\n",
        "history = model.fit(....)\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UatqCYAh3jjd"
      },
      "source": [
        "Evaluación sobre el conjunto de test (no usado para el entrenamiento). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-utxTvWSq7"
      },
      "source": [
        "#TODO - llamar a evaluate usando el conjunto de test\n",
        "result = model.evaluate(...)\n",
        "print(model.metrics_names)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}