{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57knM8jrYZ2t"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA2/blob/main/lab10/lab10.ipynb)\n",
    "\n",
    "# Práctica 10: Autoencoders\n",
    "\n",
    "## Pre-requisitos\n",
    "\n",
    "### Instalar paquetes\n",
    "\n",
    "Si la práctica requiere algún paquete de Python, habrá que incluir una celda en la que se instalen. Si usamos un paquete que se ha utilizado en prácticas anteriores, podríamos dar por supuesto que está instalado pero no cuesta nada satisfacer todas las dependencias en la propia práctica para reducir las dependencias entre ellas.\n",
    "\n",
    "### NOTA: En <font color='red'>Google Colab</font> hay que instalar los paquetes EN CADA EJECUCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkaimNJfYZ2w"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de instalación de tensorflow 2.0\n",
    "#%tensorflow_version 2.x\n",
    "# !pip3 install tensorflow  # NECESARIO SOLO SI SE EJECUTA EN LOCAL\n",
    "import tensorflow as tf\n",
    "\n",
    "# Hacemos los imports que sean necesarios\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XtPbzY_V1gG"
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "El autoencoder es un tipo de red que se utiliza para aprender codificaciones eficientes de datos sin etiquetar (lo que se conoce como aprendizaje no supervisado). Es una red que tiene el mismo tamaño en la entrada como en la salida, puesto que el objetivo de la red es reconstruír la entrada con la menor pérdida posible.\n",
    "\n",
    "Si lo que hacemos es reconstruír la entrada, ¿qué sentido tiene el usar la red? Habitualmente, **la red consta, a su mitad, de una capa con menos elementos que los datos de entrada**. Por tanto, al reconstruír los datos de la entrada a la salida, en esa capa tendremos una versión *comprimida* de la entrada, que contendrá la mayor parte de su información.\n",
    "\n",
    "Por tanto, podemos dividir un autoencoder en 3 secciones diferentes, tal y como se ve en la siguiente figura:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1yxkKZV0J0YplQAGPGJxQ2Z80Ad6L94eu)\n",
    "\n",
    "1. **Encoder:** es la parte inicial de la red, encargada de comprimir los datos de la entrada.\n",
    "1. **Code:** es la salida del encoder, contiene la versión *comprimida* de los datos de entrada.\n",
    "1. **Decoder:** se encarga de, partiendo de la salida del *Encoder*, reconstruír la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOch-CnwQttl"
   },
   "source": [
    "# Autoencoders sobre MNIST\n",
    "\n",
    "Lo que queremos hacer es entrenar un autoencoder para que nos proporcione una versión comprimida del dataset MNIST. Para ello, lo primero que tenemos que hacer es cargar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gXdWDBIEKel"
   },
   "outputs": [],
   "source": [
    "_, (x_train, y_train), = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Haz el preprocesado que necesites aquí (si lo necesitas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkaCDOGapMyl"
   },
   "source": [
    "## Crea tu propio Autoencoder\n",
    "\n",
    "Estamos a final de curso, ya deberías de ser capaz de realizar este trabajo con muy poca ayuda. ¡Es hora de que pongas en práctica todos los conocimientos de la asignatura! El diseño del autoencoder es libre (capas densas, convolucionales, ...), puedes crearlo como quieras. **El único parámetro fijo es la salida del encoder: tendrá un tamaño de 10 unidades.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xjcLa21EKen"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio encoder\n",
    "encoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dG31TKIraE7r"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio decoder. Habitualmente sigue la misma configuración del encoder, en sentido inverso.\n",
    "decoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5RQLRa2aKlY"
   },
   "outputs": [],
   "source": [
    "# TODO: crea el autoencoder como una combinación del encoder y el decoder. \n",
    "# RECUERDA: en keras se puede hacer un modelo secuencial que contenga otros modelos\n",
    "autoencoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTAr-irGaaM3"
   },
   "outputs": [],
   "source": [
    "# TODO: compila y entrena la red\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOUs41sffFPs"
   },
   "source": [
    "# Aprendizaje no supervisado\n",
    "\n",
    "Como comentábamos al inicio, los autoencoder se utilizan para el aprendizaje no supervisado, esto es, cuando no tenemos etiquetados los datos. En el dataset MNIST los tenemos etiquetados, pero vamos a operar como si no fuera así, para finalmente comprobar cómo de bien hemos agrupado los datos.\n",
    "\n",
    "**Antes de nada, obtén la representación comprimida de los datos.**\n",
    "\n",
    "**<font color='red'>PISTA:</font> si has creado correctamente la red, podrás obtener la representación simplemente obteniendo la salida del encoder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1suiZwqfBPD"
   },
   "outputs": [],
   "source": [
    "# TODO: obtén la representación comprimida de los datos\n",
    "autoencoder_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHwD7iLeWTm1"
   },
   "source": [
    "A modo de comparación, vamos a utilizar otro modelo no supervisado para obtener una representación de los datos. En este caso, haremos uso de un viejo conocido: el [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aoHeJUGEKeo"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_data = PCA(n_components=10).fit_transform(x_train.reshape((len(x_train), -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBWw_ncKh1EA"
   },
   "source": [
    "#### Visualización de los datos con t-SNE\n",
    "\n",
    "[t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) es una herramienta para visualizar datos en alta dimensionalidad. No vamos a entrar en detalle sobre cómo funciona, sólo tiene que quedar clara una cuestión: **cuanto más diferenciadas estén los clústers pertenecientes a una misma clase, mejor compresión de datos tendremos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A21tPyXTtDKG"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne_data = {\n",
    "             'PCA': TSNE(n_components=2, init='random').fit_transform(pca_data),\n",
    "             'Autoencoder': TSNE(n_components=2, init='random').fit_transform(autoencoder_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFyHhz4lhvme"
   },
   "outputs": [],
   "source": [
    "# usaremos esta función para visualizar los resultados\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def plot_embedding(X, y, title, ax):\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "    shown_images = np.array([[1.0, 1.0]])  # just something big\n",
    "    for i in range(X.shape[0]):\n",
    "        # plot every digit on the embedding\n",
    "        ax.text(\n",
    "            X[i, 0],\n",
    "            X[i, 1],\n",
    "            str(y[i]),\n",
    "            color=plt.cm.Dark2(y[i]),\n",
    "            fontdict={\"weight\": \"bold\", \"size\": 9},\n",
    "        )\n",
    "\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "names = list(tsne_data.keys())\n",
    "\n",
    "for name, ax in zip(names, axs.ravel()):\n",
    "    if name is None:\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "    title = f\"{name}\"\n",
    "    plot_embedding(tsne_data[name], y_train, title, ax)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cpyBP_MZdj-"
   },
   "source": [
    "Deberías poder ver una buena separación entre los números. Si tu autoencoder no mejora los resultados de PCA, deberás mejorarlo!\n",
    "\n",
    "## Evaluación empírica\n",
    "\n",
    "Ya hemos visto visualmente cómo de buena es nuestra compresión, ahora toca verlo de manera empírica. Para ello, vamos a utilizar uno de los algoritmos de clústering más clásicos: [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCuqvBRlXcSa"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pca_kmeans = KMeans(n_clusters=10, random_state=26).fit_predict(pca_data)\n",
    "autoencoder_kmeans = KMeans(n_clusters=10, random_state=26).fit_predict(autoencoder_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXV-9QjtvWeJ"
   },
   "source": [
    "Para evaluar cómo de bien lo ha hecho, hay que tener en cuenta que, al ser no supervisado, puede asignar etiquetas distintas para las que tenemos en nuestro dataset. Por ello, necesitamos usar una función para asignar la correspondencia **etiqueta dataset - etiqueta clúster**. En nuestro caso, vamos a utilizar el *Normalized Mutual Info Score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrEd7tCiwzaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "print('PCA NMI:', normalized_mutual_info_score(pca_kmeans, y_train))\n",
    "print('Autoencoder NMI:', normalized_mutual_info_score(autoencoder_kmeans, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77mBj__rcrui"
   },
   "source": [
    "### Si el NMI de tu autoencoder es inferior al del PCA, ¡trabaja para mejorarlo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIEsuejQv4mP"
   },
   "source": [
    "# ¡ENHORABUENA! Has completado la práctica de Autoencoders.\n",
    "\n",
    "# ¿Deseas saber más?\n",
    "\n",
    "Los autoencoders son una herramienta muy potente, no sólo para la compresión de datos. Por ejemplo, también se utilizan para la generación de datos artificiales, con los conocidos *Variational Autoencoders* [VAE](https://www.youtube.com/watch?v=Q1XuXwPVFko).\n",
    "\n",
    "El aprendizaje no supervisado no se limita sólo a clústering. Actualmente está en auge una disciplina llamada **Self-supervised learning**, que nos permite hacer cosas sin supervisar increíbles hace menos de un año, tales como [DINO](https://www.youtube.com/watch?v=8I1RelnsgMw), creado por Facebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QIu2fE3tIHA"
   },
   "source": [
    "# Trabajo extra\n",
    "\n",
    "¿Has probado a hacer el autoencoder totalmente convolucional? Para el *decoder* puedes usar las funciones [UpSampling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D) o [Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMavrtMX_7V7"
   },
   "outputs": [],
   "source": [
    "# TODO: escribe el código para el trabajo extra sin ayuda. Usa todos los bloques de código que quieras."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "10_autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
