{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4_parte1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GxLyX9vdCnf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA2/blob/main/lab4/lab4_parte1.ipynb)\n",
        "# Práctica 4: Redes neuronales usando Keras con Regularización\n",
        "## Parte 1. Early Stopping\n",
        "### Overfitting\n",
        "El problema del sobreajuste (*overfitting*) consiste en que la solución aprendida se ajusta muy bien a los datos de entrenamiento, pero no generaliza adecuadamente ante la aparición de nuevos datos. \n",
        "\n",
        "# Regularización\n",
        "\n",
        "Una vez diagnosticado el sobreajuste, es hora de probar diferentes técnicas que intenten reducir la varianza, sin incrementar demasiado el sesgo y, con ello, el modelo generaliza mejor. Las técnicas de regularización que vamos a ver en este laboratorio son:\n",
        "1. *Early stopping*. Detiene el entrenamiento de la red cuando aumenta el error.\n",
        "1. Penalización basada\ten\tla\tnorma\tde\tlos\tparámetros (tanto norma L1 como L2). \n",
        "1. *Dropout*. Ampliamente utilizada en aprendizaje profundo, \"desactiva\" algunas neuronas para evitar el sobreajuste.\n",
        "\n",
        "En esta primera parte del Laboratorio 4 nos centraremos en **Early Stopping**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zjhho6Jb6-j"
      },
      "source": [
        "## Pre-requisitos. Instalar paquetes\n",
        "\n",
        "Para la primera parte de este Laboratorio 4 necesitaremos TensorFlow, TensorFlow-Datasets y otros paquetes para inicializar la semilla y poder reproducir los resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjX2mh1-GSga"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "#Fijamos la semilla para poder reproducir los resultados\n",
        "seed=1234\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyTV4jfNeiRk"
      },
      "source": [
        "Además, cargamos también APIs que vamos a emplear para que el código quede más legible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3-nLMx-enlq"
      },
      "source": [
        "#API de Keras, modelo Sequential y las capas que vamos a usar en nuestro modelo\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import InputLayer\n",
        "from keras.layers import Dense \n",
        "#Para mostrar gráficas\n",
        "from matplotlib import pyplot\n",
        "\n",
        "#Necesario para el EarlyStopping\n",
        "from keras.callbacks import EarlyStopping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd9GpQD5WVY4"
      },
      "source": [
        "## Cargamos el conjunto de datos\n",
        "\n",
        "De nuevo, seguimos empleando el conjunto *german_credit_numeric* ya empleado en los laboratorios anteriores, aunque esta vez lo dividimos para tener un subconjunto de entrenamiento, otro de validación (que nos servirá para detener el entrenamiento) y otro de test para evaluar el rendimiento del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpsZlN_mEj7D"
      },
      "source": [
        "# Cargamos el conjunto de datos\n",
        "ds_train = tfds.load('german_credit_numeric', split='train[:40%]',  as_supervised=True).batch(128)\n",
        "ds_val = tfds.load('german_credit_numeric', split='train[40%:50%]', as_supervised=True).batch(128)\n",
        "ds_test = tfds.load('german_credit_numeric', split='train[50%:]', as_supervised=True).batch(128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNSojR94dP3y"
      },
      "source": [
        "También vamos a establecer la función de pérdida, el algoritmo que vamos a emplear para el entrenamiento y la métrica que nos servirá para evaluar el rendimiento del modelo entrenado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXz3n9daGXjG"
      },
      "source": [
        "#Indicamos la función de perdida, el algoritmo de optimización y la métrica para evaluar el rendimiento \n",
        "fn_perdida = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizador = tf.keras.optimizers.Adam(0.001)\n",
        "metrica = tf.keras.metrics.AUC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENqWLaw7fuxl"
      },
      "source": [
        "## Creamos un modelo *Sequential*\n",
        "Creamos un modelo *Sequential* tal y como se ha hecho en el Laboratorio 3. Parte 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrIOT-4DmRuu"
      },
      "source": [
        "tamano_entrada = 24\n",
        "h0_size = 20\n",
        "h1_size = 10\n",
        "h2_size = 5\n",
        "#TODO - define el modelo Sequential\n",
        "model = ...\n",
        "#TODO - incluye la capa de entrada y las 4 capas Dense del modelo\n",
        "......\n",
        "\n",
        "#Construimos el modelo y mostramos \n",
        "model.build()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1AeI0KUuTcC"
      },
      "source": [
        "Completar el método *compile*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U_0GMdHzhpP"
      },
      "source": [
        "#TODO - indicar los parametros del método compile\n",
        "model.compile(loss=fn_perdida,\n",
        "              optimizer=optimizador,\n",
        "              metrics=[metrica])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx2nvo6G0Qvn"
      },
      "source": [
        "Hacemos una llamada al método *fit* usando el conjunto de entrenamiento como entrada, indicando el número de epochs y, además,  incluyendo el argumento *validation_data* que permite usar un subconjunto de datos para validar. Las diferencias entre entrenamiento y validación se pueden apreciar en el gráfico.\n",
        "\n",
        "**NOTA**: Observad las diferencias de resultado entre entrenamiento, validación y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EzQDyKfGfuu"
      },
      "source": [
        "#Establecemos el número de epochs\n",
        "num_epochs =  700\n",
        "\n",
        "# Guardamos los pesos antes de entrenar, para poder resetear el modelo posteriormente y hacer comparativas.\n",
        "pesos_preentrenamiento = model.get_weights()\n",
        "\n",
        "#TODO - entrenar el modelo usando como entradas el conjunto de entrenamiento, \n",
        "#indicando el número de epochs y el conjunto de validación\n",
        "history = model.fit(....)\n",
        "\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlO-eiQzZw8M"
      },
      "source": [
        "#TODO - llamar a evaluate usando el conjunto de test, guardando el resultado\n",
        "result = model.evaluate(.....) \n",
        "print(model.metrics_names)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0LLJgsgdJc"
      },
      "source": [
        "## Usando Early Stopping en el entrenamiento\n",
        "\n",
        "Keras nos facilita un *Callback* para realizar la parada temprana (*keras.callbacks.EarlyStopping*).  De este modo, podemos parar el entrenamiento cuando una determinada medida (especificada en el argumento *monitor*) empeore su rendimiento (el argumento *mode* nos dirá si se espera que dicha medida se minimice, *min*, o maximice, *max*). Opcionalmente, el usuario puede proporcionar el argumento *patience* para especificar cuantas *epochs* debe esperar el entrenamiento antes de detenerse.\n",
        "\n",
        "**TO-DO**: Realizar varias veces el entrenamiento, cambiando los distintos parámetros para ver las diferencias en el aprendizaje. ¿Se para siempre en el mismo *epoch*? Comprobar el rendimiento en el conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfJTI4GghM3i"
      },
      "source": [
        "# simple early stopping\n",
        "#TODO- indica la medida a monitorizar,  el modo y la paciencia\n",
        "es = EarlyStopping(\n",
        "    monitor=....\n",
        "    mode=...\n",
        "    patience=...\n",
        ")\n",
        "\n",
        "# Antes de entrenar, olvidamos el entrenamiento anterior restaurando los pesos iniciales\n",
        "model.set_weights(pesos_preentrenamiento)\n",
        "\n",
        "#TODO - entrenar el modelo usando como entradas el conjunto de entrenamiento, \n",
        "#indicando el número de epochs, el conjunto de validación y la callback para el EarlyStopping\n",
        "history = model.fit(...., callbacks=[es])\n",
        "\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcjua_KlWymG"
      },
      "source": [
        "Evaluación sobre el conjunto de test (no usado para el entrenamiento)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-utxTvWSq7"
      },
      "source": [
        "#TODO - llamar a evaluate usando el conjunto de test, guardando el resultado\n",
        "result = model.evaluate(....) \n",
        "print(model.metrics_names)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}