{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GxLyX9vdCnf"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA2/blob/main/lab6/lab6-parte1.ipynb)\n",
    "# Práctica 6: Redes neuronales convolucionales - Parte 1 - FF vs CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zjhho6Jb6-j"
   },
   "source": [
    "### Pre-requisitos. Instalar paquetes\n",
    "\n",
    "Para la primera parte de este Laboratorio 6 necesitaremos TensorFlow y TensorFlow-Datasets. Además, como habitualmente, fijaremos la semilla aleatoria para asegurar la reproducibilidad de los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjX2mh1-GSga"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "#Fijamos la semilla para poder reproducir los resultados\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "seed=1234567\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyTV4jfNeiRk"
   },
   "source": [
    "Además, cargamos también APIs que vamos a emplear para que el código quede más legible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3-nLMx-enlq"
   },
   "outputs": [],
   "source": [
    "#API de Keras, modelo Sequential y la capa Dense \n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "#Para mostrar gráficas\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd9GpQD5WVY4"
   },
   "source": [
    "### Carga del conjunto de datos\n",
    "\n",
    "En esta ocasión trabajaremos con el conjunto de imágenes *mnist*, que representa dígitos escritos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# El parámetro with_info=True nos permite acceder a información sobre el dataset\n",
    "# Carga el conjunto de datos mnist. Usaremos el primer 80% de la partición train para ds_train y el 20% restante para ds_val. ds_test tomará la partición test.\n",
    "(ds_train, ds_test, ds_val), ds_info = tfds.load(..., with_info=True, as_supervised=True)\n",
    "\n",
    "\n",
    "# En dicha información se encuentran los nombres de las clases y las dimensiones de las imágenes\n",
    "NUM_CLASSES = ds_info.features['label'].num_classes\n",
    "nombres_clases = ds_info.features['label'].names\n",
    "dimensiones = ds_info.features['image'].shape\n",
    "print(\"Hay %d clases\"%NUM_CLASSES)\n",
    "\n",
    "# Para comprobar que se ha cargado tomamos un elemento y lo mostramos\n",
    "ej_imagen, ej_etiqueta = next(iter(ds_train.take(1)))\n",
    "pyplot.imshow(ej_imagen[:,:,0])\n",
    "pyplot.xlabel(nombres_clases[ej_etiqueta.numpy()])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado de los datos\n",
    "\n",
    "La etiqueta que nos suministra el dataset es numérica. Sin embargo, nosotros prediciremos un vector con tantas componentes como clases, donde cada componente estima la probabilidad de que el ejemplo pertenezca a una clase. Por tanto, hay que convertir la etiqueta suministrada a codificación one_hot con la función [tf.one_hot](https://www.tensorflow.org/api_docs/python/tf/one_hot)\n",
    "\n",
    "Por otra parte, cada color de cada pixel de la imagen viene indicado con un entero entre 0 y 255. Para entrenar es preferible que se indiquen con números entre 0 y 1, por lo que deberemos escalar la imagen dividiendo su tensor por 255.\n",
    "\n",
    "**PISTA: el número de clases se ha almacenado anteriormente en la variable NUM_CLASSES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensiones = ej_imagen.shape\n",
    "\n",
    "## TODO: convierte las etiquetas a tipo one hot.\n",
    "ds_train = ds_train.map(lambda image, label: (tf.cast(image,tf.float32)/255.0, ...))\n",
    "ds_test = ...\n",
    "ds_val = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando los datos con un red neuronal feed-forward\n",
    "\n",
    "Vamos a modelar los datos con una red feed-forward que tenga capas de 40, 25 y 16 unidades (todas con activación ReLU). Debemos tener en cuenta que las imágenes son tensores de dimensión 3 (su `shape` es (28,28,1)), mientras que la entrada de nuestras capas Dense debe ser un tensor de dimensión 1. Para adecuar la entrada a lo que necesitamos, vamos a \"aplanar\" los tensores de las imágenes, que pasarán de `shape` (28,28,1) a `shape` (784). Utilizaremos para ello una capa `Flatten`.\n",
    "\n",
    "Por último, la salida de nuestro modelo debe tener tantas componentes como clases distintas tiene el conjunto. Como queremos que la salida aproxime la probabilidad de las distintas clases, lo habitual sería poner una función de activación *softmax*, pero en este caso, por razones de eficiencia del entrenamiento, es mejor dejar una salida lineal y posteriormente indicarle a la función de pérdida que las salidas vienen en ese formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KrIOT-4DmRuu",
    "outputId": "79dba569-e5e5-426f-9a87-57757db7d363"
   },
   "outputs": [],
   "source": [
    "# TODO - Crea el modelo descrito\n",
    "model = ...\n",
    "\n",
    "#Construimos el modelo y mostramos \n",
    "model.build()\n",
    "print(model.summary())\n",
    "\n",
    "# VERIFICACIÓN\n",
    "assert model.count_params()==33011, 'Revisa la arquitectura de tu modelo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNSojR94dP3y"
   },
   "source": [
    "### Entrenamiento del modelo\n",
    "Vamos a establecer la función de pérdida, el optimizador (Adam con el LR por defecto) y la métrica que nos servirá para evaluar el rendimiento del modelo entrenado (precisión categórica).\n",
    "\n",
    "Como intentamos predecir una clase entre varias, nuestra función de pérdida debe ser la [entropía cruzada categórica](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy). Aquí es donde le indicaremos que la salida de nuestra red no son valores entre 0 y 1, sino que son valores reales que deben ser utilizados como *logits* por la función softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - Compila el modelo con los parámetros indicados\n",
    "model.compile(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rx2nvo6G0Qvn"
   },
   "source": [
    "Como siempre, entrenaremos el modelo usando `model.fit`. Para ello, previamente debemos indicar a nuestro dataset que haga lotes de 128 elementos. Le indicaremos también que baraje los datos utilizando un buffer de 5 veces el tamaño de lote. La aleatorización debe hacerse antes de la partición en lotes, para que se aleatoricen los elementos y no los lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Baraja y trocea los datasets en lotes.\n",
    "ds_train_batch = ...\n",
    "ds_val_batch = ...\n",
    "\n",
    "# TODO - Entrena el modelo. Con 16 epochs será suficiente.\n",
    "# Haz que nos ofrezca también las mediciones de pérdida y precisión sobre el conjunto de validación,\n",
    "# para saber si el modelo está sobreajustando.\n",
    "history = model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.title('Loss')\n",
    "pyplot.show()\n",
    "\n",
    "# plot training history\n",
    "pyplot.plot(history.history['categorical_accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_categorical_accuracy'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación del rendimiento\n",
    "Aprovecharemos el conjunto de test para comprobar la capacidad de generalización de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Evalúa el modelo sobre el conjunto de test. Previamente deberás hacer lotes con el conjunto de test.\n",
    "print(\"Evaluación sobre el conjunto TEST:\")\n",
    "ds_test_batch = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo ha ido correctamente deberías haber obtenido un valor de precisión sobre el conjunto de test comparable a los obtenidos con los conjuntos de entrenamiento y validación, lo que indica que el modelo generaliza bien a otros datos del conjunto original pero... ¿tenemos un buen modelo?\n",
    "\n",
    "Vamos a comprobar la robustez del modelo haciendo pequeños desplazamientos de las imágenes originales. Utilizaremos un pequeño modelo que aplique una traslación aleatoria de hasta un 10% del tamaño de la imagen a cada una de las imágenes de test. Nos ayudaremos de la capa `RandomTranslation` de preprocesado de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import RandomTranslation\n",
    "\n",
    "translator = Sequential(\n",
    "                [RandomTranslation(height_factor=0.1, width_factor=0.1)]\n",
    "            )\n",
    "\n",
    "# TODO - Aplica la red translator a cada imagen\n",
    "ds_test_desplazado = ds_test_batch.map(lambda image, label: (...,label))\n",
    "\n",
    "\n",
    "# TODO - Toma un elemento de ds_test_desplazado y muéstralo con pyplot\n",
    "ej_imagen_desplazada = next(iter(ds_test_desplazado.take(1)))[0][0]\n",
    "\n",
    "pyplot.imshow(ej_imagen_desplazada[:,:,0])\n",
    "pyplot.xlabel(nombres_clases[ej_etiqueta.numpy()])\n",
    "pyplot.title('imagen desplazada')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos ahora la precisión sobre este nuevo conjunto de imágenes que han sido ligeramente desplazadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluación sobre el conjunto TEST DESPLAZADO:\")\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo ha ido bien, deberías haber comprobado que estas pequeñas traslaciones son suficientes para que la precisión del modelo baje sustancialmente. Las redes feed-forward no son robustas ante este tipo de perturbaciones.\n",
    "\n",
    "## Comparativa con una red convolucional\n",
    "\n",
    "Declara ahora un modelo convolucional con la siguiente arquitectura:\n",
    " 1. [Convolución 2D](https://keras.io/api/layers/convolution_layers/convolution2d/) de 8 filtros y tamaño de kernel 3, con activación ReLU\n",
    " 1. [Pooling 2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/) tomando el máximo de cada grupo de 2x2\n",
    " 1. [Convolución 2D](https://keras.io/api/layers/convolution_layers/convolution2d/) de 8 filtros y tamaño de kernel 3, con activación ReLU\n",
    " 1. [Pooling 2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/) tomando el máximo de cada grupo de 2x2\n",
    " 1. Capa Densa (requiere aplanado previo) de 32 unidades y activación ReLU\n",
    " \n",
    "Ejecuta la siguiente celda y repite el compilado, entrenamiento y verificaciones posteriores para observar la diferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "model = ...\n",
    "\n",
    "#Construimos el modelo y mostramos \n",
    "model.build()\n",
    "print(model.summary())\n",
    "\n",
    "# VERIFICACIÓN\n",
    "assert model.count_params()==7426, 'Revisa la arquitectura de tu modelo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexiones sobre la comparativa\n",
    " - ¿Qué has observado en el rendimiento?\n",
    " - ¿Cuántos parámetros tiene la red convolucional respecto a la *feed-forward*\n",
    " - ¿Cómo ha cambiado el tiempo de ejecución?\n",
    " - ¿Es más robusta frente a los desplazamientos esta red?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab4_parte1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
